{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting docling"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading docling-2.5.1-py3-none-any.whl (84 kB)\n",
      "     ---------------------------------------- 84.4/84.4 kB 2.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in c:\\users\\david\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from docling) (4.12.3)\n",
      "Requirement already satisfied: certifi>=2024.7.4 in c:\\users\\david\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from docling) (2024.8.30)\n",
      "Collecting deepsearch-glm<0.27.0,>=0.26.1\n",
      "  Downloading deepsearch_glm-0.26.1-cp311-cp311-win_amd64.whl (7.9 MB)\n",
      "     ---------------------------------------- 7.9/7.9 MB 5.8 MB/s eta 0:00:00\n",
      "Collecting docling-core<3.0.0,>=2.3.0\n",
      "  Downloading docling_core-2.3.2-py3-none-any.whl (71 kB)\n",
      "     ---------------------------------------- 71.4/71.4 kB 3.8 MB/s eta 0:00:00\n",
      "Collecting docling-ibm-models<3.0.0,>=2.0.3\n",
      "  Downloading docling_ibm_models-2.0.3-py3-none-any.whl (65 kB)\n",
      "     ---------------------------------------- 66.0/66.0 kB 3.7 MB/s eta 0:00:00\n",
      "Collecting docling-parse<3.0.0,>=2.0.2\n",
      "  Downloading docling_parse-2.0.3-cp311-cp311-win_amd64.whl (23.1 MB)\n",
      "     ---------------------------------------- 23.1/23.1 MB 5.0 MB/s eta 0:00:00\n",
      "Collecting easyocr<2.0,>=1.7\n",
      "  Downloading easyocr-1.7.2-py3-none-any.whl (2.9 MB)\n",
      "     ---------------------------------------- 2.9/2.9 MB 5.5 MB/s eta 0:00:00\n",
      "Collecting filetype<2.0.0,>=1.2.0\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: huggingface_hub<1,>=0.23 in c:\\users\\david\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from docling) (0.25.1)\n",
      "Collecting marko<3.0.0,>=2.1.2\n",
      "  Downloading marko-2.1.2-py3-none-any.whl (42 kB)\n",
      "     ---------------------------------------- 42.1/42.1 kB ? eta 0:00:00\n",
      "Requirement already satisfied: pandas<3.0.0,>=2.1.4 in c:\\users\\david\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from docling) (2.2.3)\n",
      "Collecting pyarrow<17.0.0,>=16.1.0\n",
      "  Downloading pyarrow-16.1.0-cp311-cp311-win_amd64.whl (25.9 MB)\n",
      "     ---------------------------------------- 25.9/25.9 MB 5.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in c:\\users\\david\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from docling) (2.9.2)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.3.0 in c:\\users\\david\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from docling) (2.5.2)\n",
      "Requirement already satisfied: pypdfium2<5.0.0,>=4.30.0 in c:\\users\\david\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from docling) (4.30.0)\n",
      "Collecting python-docx<2.0.0,>=1.1.2\n",
      "  Downloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
      "     -------------------------------------- 244.3/244.3 kB 3.7 MB/s eta 0:00:00\n",
      "Collecting python-pptx<2.0.0,>=1.0.2\n",
      "  Downloading python_pptx-1.0.2-py3-none-any.whl (472 kB)\n",
      "     -------------------------------------- 472.8/472.8 kB 5.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.3 in c:\\users\\david\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from docling) (2.32.3)\n",
      "Collecting rtree<2.0.0,>=1.3.0\n",
      "  Downloading Rtree-1.3.0-py3-none-win_amd64.whl (377 kB)\n",
      "     -------------------------------------- 377.5/377.5 kB 4.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.14.1 in c:\\users\\david\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from docling) (1.14.1)\n",
      "Collecting typer<0.13.0,>=0.12.5\n",
      "  Downloading typer-0.12.5-py3-none-any.whl (47 kB)\n",
      "     ---------------------------------------- 47.3/47.3 kB 2.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\david\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from beautifulsoup4<5.0.0,>=4.12.3->docling) (2.6)\n",
      "Collecting docutils!=0.21\n",
      "  Downloading docutils-0.21.2-py3-none-any.whl (587 kB)\n",
      "     -------------------------------------- 587.4/587.4 kB 6.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.4 in c:\\users\\david\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from deepsearch-glm<0.27.0,>=0.26.1->docling) (1.26.4)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.0 in c:\\users\\david\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from deepsearch-glm<0.27.0,>=0.26.1->docling) (1.0.1)\n",
      "Requirement already satisfied: pywin32<308,>=307 in c:\\users\\david\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from deepsearch-glm<0.27.0,>=0.26.1->docling) (307)\n",
      "Requirement already satisfied: rich<14.0.0,>=13.7.0 in c:\\users\\david\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from deepsearch-glm<0.27.0,>=0.26.1->docling) (13.9.3)\n",
      "Collecting tabulate>=0.8.9\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.64.0 in c:\\users\\david\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from deepsearch-glm<0.27.0,>=0.26.1->docling) (4.66.5)\n",
      "Collecting jsonref<2.0.0,>=1.1.0\n",
      "  Downloading jsonref-1.1.0-py3-none-any.whl (9.4 kB)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.16.0 in c:\\users\\david\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from docling-core<3.0.0,>=2.3.0->docling) (4.23.0)\n",
      "Requirement already satisfied: pillow<11.0.0,>=10.3.0 in c:\\users\\david\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from docling-core<3.0.0,>=2.3.0->docling) (10.4.0)\n",
      "Collecting jsonlines<4.0.0,>=3.1.0\n",
      "  Downloading jsonlines-3.1.0-py3-none-any.whl (8.6 kB)\n",
      "Collecting lxml<5.0.0,>=4.9.1\n",
      "  Downloading lxml-4.9.4-cp311-cp311-win_amd64.whl (3.8 MB)\n",
      "     ---------------------------------------- 3.8/3.8 MB 4.8 MB/s eta 0:00:00\n",
      "Collecting mean_average_precision<2022.0.0.0,>=2021.4.26.0\n",
      "  Downloading mean_average_precision-2021.4.26.0-py3-none-any.whl (14 kB)\n",
      "Collecting opencv-python-headless<5.0.0.0,>=4.6.0.66\n",
      "  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-win_amd64.whl (38.8 MB)\n",
      "     ---------------------------------------- 38.8/38.8 MB 5.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: torch<3.0.0,>=2.2.2 in c:\\users\\david\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from docling-ibm-models<3.0.0,>=2.0.3->docling) (2.4.1)\n",
      "Collecting torchvision<1,>=0\n",
      "  Downloading torchvision-0.20.1-cp311-cp311-win_amd64.whl (1.6 MB)\n",
      "     ---------------------------------------- 1.6/1.6 MB 5.9 MB/s eta 0:00:00\n",
      "Collecting scikit-image\n",
      "  Downloading scikit_image-0.24.0-cp311-cp311-win_amd64.whl (12.8 MB)\n",
      "     ---------------------------------------- 12.8/12.8 MB 5.8 MB/s eta 0:00:00\n",
      "Collecting python-bidi\n",
      "  Downloading python_bidi-0.6.3-cp311-none-win_amd64.whl (157 kB)\n",
      "     -------------------------------------- 157.2/157.2 kB 4.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: PyYAML in c:\\users\\david\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from easyocr<2.0,>=1.7->docling) (6.0.2)\n",
      "Collecting Shapely\n",
      "  Downloading shapely-2.0.6-cp311-cp311-win_amd64.whl (1.4 MB)\n",
      "     ---------------------------------------- 1.4/1.4 MB 5.7 MB/s eta 0:00:00\n",
      "Collecting pyclipper\n",
      "  Downloading pyclipper-1.3.0.post6-cp311-cp311-win_amd64.whl (110 kB)\n",
      "     -------------------------------------- 110.4/110.4 kB 6.7 MB/s eta 0:00:00\n",
      "Collecting ninja\n",
      "  Using cached ninja-1.11.1.1-py2.py3-none-win_amd64.whl (312 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\david\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface_hub<1,>=0.23->docling) (3.15.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\david\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface_hub<1,>=0.23->docling) (2024.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\david\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface_hub<1,>=0.23->docling) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\david\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface_hub<1,>=0.23->docling) (4.12.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\david\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas<3.0.0,>=2.1.4->docling) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\david\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas<3.0.0,>=2.1.4->docling) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\david\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas<3.0.0,>=2.1.4->docling) (2024.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\david\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3.0.0,>=2.0.0->docling) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\david\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3.0.0,>=2.0.0->docling) (2.23.4)\n",
      "Collecting XlsxWriter>=0.5.7\n",
      "  Downloading XlsxWriter-3.2.0-py3-none-any.whl (159 kB)\n",
      "     -------------------------------------- 159.9/159.9 kB 4.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\david\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.32.3->docling) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\david\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.32.3->docling) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\david\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.32.3->docling) (2.2.2)\n",
      "Collecting click>=8.0.0\n",
      "  Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "     ---------------------------------------- 97.9/97.9 kB 2.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\david\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typer<0.13.0,>=0.12.5->docling) (1.5.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\david\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from click>=8.0.0->typer<0.13.0,>=0.12.5->docling) (0.4.6)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\david\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonlines<4.0.0,>=3.1.0->docling-ibm-models<3.0.0,>=2.0.3->docling) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\david\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema<5.0.0,>=4.16.0->docling-core<3.0.0,>=2.3.0->docling) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\david\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema<5.0.0,>=4.16.0->docling-core<3.0.0,>=2.3.0->docling) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\david\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema<5.0.0,>=4.16.0->docling-core<3.0.0,>=2.3.0->docling) (0.20.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\david\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3.0.0,>=2.1.4->docling) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\david\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich<14.0.0,>=13.7.0->deepsearch-glm<0.27.0,>=0.26.1->docling) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\david\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich<14.0.0,>=13.7.0->deepsearch-glm<0.27.0,>=0.26.1->docling) (2.18.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\david\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<3.0.0,>=2.0.3->docling) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\david\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<3.0.0,>=2.0.3->docling) (2.8.8)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\david\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<3.0.0,>=2.0.3->docling) (3.1.4)\n",
      "Collecting torch<3.0.0,>=2.2.2\n",
      "  Downloading torch-2.5.1-cp311-cp311-win_amd64.whl (203.1 MB)\n",
      "     -------------------------------------- 203.1/203.1 MB 4.0 MB/s eta 0:00:00\n",
      "Collecting sympy\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "     ---------------------------------------- 6.2/6.2 MB 5.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\david\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch<3.0.0,>=2.2.2->docling-ibm-models<3.0.0,>=2.0.3->docling) (1.3.0)\n",
      "Collecting imageio>=2.33\n",
      "  Downloading imageio-2.36.0-py3-none-any.whl (315 kB)\n",
      "     -------------------------------------- 315.4/315.4 kB 4.8 MB/s eta 0:00:00\n",
      "Collecting tifffile>=2022.8.12\n",
      "  Downloading tifffile-2024.9.20-py3-none-any.whl (228 kB)\n",
      "     -------------------------------------- 228.2/228.2 kB 3.5 MB/s eta 0:00:00\n",
      "Collecting lazy-loader>=0.4\n",
      "  Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\david\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.7.0->deepsearch-glm<0.27.0,>=0.26.1->docling) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\david\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch<3.0.0,>=2.2.2->docling-ibm-models<3.0.0,>=2.0.3->docling) (3.0.0)\n",
      "Installing collected packages: python-bidi, pyclipper, ninja, filetype, XlsxWriter, tifffile, tabulate, sympy, Shapely, rtree, pyarrow, opencv-python-headless, marko, lxml, lazy-loader, jsonref, jsonlines, imageio, docutils, click, torch, scikit-image, python-pptx, python-docx, docling-parse, typer, torchvision, mean_average_precision, easyocr, docling-ibm-models, docling-core, deepsearch-glm, docling\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.13.3\n",
      "    Uninstalling sympy-1.13.3:\n",
      "      Successfully uninstalled sympy-1.13.3\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 18.0.0\n",
      "    Uninstalling pyarrow-18.0.0:\n",
      "      Successfully uninstalled pyarrow-18.0.0\n",
      "  Attempting uninstall: lxml\n",
      "    Found existing installation: lxml 5.3.0\n",
      "    Uninstalling lxml-5.3.0:\n",
      "      Successfully uninstalled lxml-5.3.0\n",
      "  Attempting uninstall: click\n",
      "    Found existing installation: click 7.1.2\n",
      "    Uninstalling click-7.1.2:\n",
      "      Successfully uninstalled click-7.1.2\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.4.1\n",
      "    Uninstalling torch-2.4.1:\n",
      "      Successfully uninstalled torch-2.4.1\n",
      "Successfully installed Shapely-2.0.6 XlsxWriter-3.2.0 click-8.1.7 deepsearch-glm-0.26.1 docling-2.5.1 docling-core-2.3.2 docling-ibm-models-2.0.3 docling-parse-2.0.3 docutils-0.21.2 easyocr-1.7.2 filetype-1.2.0 imageio-2.36.0 jsonlines-3.1.0 jsonref-1.1.0 lazy-loader-0.4 lxml-4.9.4 marko-2.1.2 mean_average_precision-2021.4.26.0 ninja-1.11.1.1 opencv-python-headless-4.10.0.84 pyarrow-16.1.0 pyclipper-1.3.0.post6 python-bidi-0.6.3 python-docx-1.1.2 python-pptx-1.0.2 rtree-1.3.0 scikit-image-0.24.0 sympy-1.13.1 tabulate-0.9.0 tifffile-2024.9.20 torch-2.5.1 torchvision-0.20.1 typer-0.12.5\n"
     ]
    }
   ],
   "source": [
    "!pip install docling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\David\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Fetching 9 files:   0%|          | 0/9 [00:00<?, ?it/s]c:\\Users\\David\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:147: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\David\\.cache\\huggingface\\hub\\models--ds4sd--docling-models. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Fetching 9 files: 100%|██████████| 9/9 [01:44<00:00, 11.58s/it]\n",
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "Downloading detection model, please wait. This may take several minutes depending upon your network connection.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: |██████████████████████████████████████████████████| 100.0% Complete"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading recognition model, please wait. This may take several minutes depending upon your network connection.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: |██████████████████████████████████████████████████| 100.0% Complete<!-- image -->\n",
      "\n",
      "## Docling Technical Report\n",
      "\n",
      "Version 1.0\n",
      "\n",
      "Christoph Auer Maksym Lysak Ahmed Nassar Michele Dolfi Nikolaos Livathinos Panos Vagenas Cesar Berrospi Ramis Matteo Omenetti Fabian Lindlbauer Kasper Dinkla Lokesh Mishra Yusik Kim Shubham Gupta Rafael Teixeira de Lima Valery Weber Lucas Morin Ingmar Meijer Viktor Kuropiatnyk Peter W. J. Staar\n",
      "\n",
      "AI4K Group, IBM Research Ruschlikon, Switzerland\n",
      "\n",
      "## Abstract\n",
      "\n",
      "This technical report introduces Docling , an easy to use, self-contained, MITlicensed open-source package for PDF document conversion. It is powered by state-of-the-art specialized AI models for layout analysis (DocLayNet) and table structure recognition (TableFormer), and runs efficiently on commodity hardware in a small resource budget. The code interface allows for easy extensibility and addition of new features and models.\n",
      "\n",
      "## 1 Introduction\n",
      "\n",
      "Converting PDF documents back into a machine-processable format has been a major challenge for decades due to their huge variability in formats, weak standardization and printing-optimized characteristic, which discards most structural features and metadata. With the advent of LLMs and popular application patterns such as retrieval-augmented generation (RAG), leveraging the rich content embedded in PDFs has become ever more relevant. In the past decade, several powerful document understanding solutions have emerged on the market, most of which are commercial software, cloud offerings [3] and most recently, multi-modal vision-language models. As of today, only a handful of open-source tools cover PDF conversion, leaving a significant feature and quality gap to proprietary solutions.\n",
      "\n",
      "With Docling , we open-source a very capable and efficient document conversion tool which builds on the powerful, specialized AI models and datasets for layout analysis and table structure recognition we developed and presented in the recent past [12, 13, 9]. Docling is designed as a simple, self-contained python library with permissive license, running entirely locally on commodity hardware. Its code architecture allows for easy extensibility and addition of new features and models.\n",
      "\n",
      "Here is what Docling delivers today:\n",
      "\n",
      "- · Converts PDF documents to JSON or Markdown format, stable and lightning fast\n",
      "- · Understands detailed page layout, reading order, locates figures and recovers table structures\n",
      "- · Extracts metadata from the document, such as title, authors, references and language\n",
      "- · Optionally applies OCR, e.g. for scanned PDFs\n",
      "- · Can be configured to be optimal for batch-mode (i.e high throughput, low time-to-solution) or interactive mode (compromise on efficiency, low time-to-solution)\n",
      "- · Can leverage different accelerators (GPU, MPS, etc).\n",
      "\n",
      "## 2 Getting Started\n",
      "\n",
      "To use Docling, you can simply install the docling package from PyPI. Documentation and examples are available in our GitHub repository at github.com/DS4SD/docling. All required model assets 1 are downloaded to a local huggingface datasets cache on first use, unless you choose to pre-install the model assets in advance.\n",
      "\n",
      "Docling provides an easy code interface to convert PDF documents from file system, URLs or binary streams, and retrieve the output in either JSON or Markdown format. For convenience, separate methods are offered to convert single documents or batches of documents. A basic usage example is illustrated below. Further examples are available in the Doclign code repository.\n",
      "\n",
      "```\n",
      "from docling.document\\_converter import DocumentConverter source = \"https :// arxiv.org/pdf /2206.01062\" # PDF path or URL converter = DocumentConverter () result = converter.convert\\_single(source) print(result.render\\_as\\_markdown ()) # output: \"## DocLayNet: A Large Human -Annotated Dataset for Document -Layout Analysis [...]\"\n",
      "```\n",
      "\n",
      "Optionally, you can configure custom pipeline features and runtime options, such as turning on or off features (e.g. OCR, table structure recognition), enforcing limits on the input document size, and defining the budget of CPU threads. Advanced usage examples and options are documented in the README file. Docling also provides a Dockerfile to demonstrate how to install and run it inside a container.\n",
      "\n",
      "## 3 Processing pipeline\n",
      "\n",
      "Docling implements a linear pipeline of operations, which execute sequentially on each given document (see Fig. 1). Each document is first parsed by a PDF backend, which retrieves the programmatic text tokens, consisting of string content and its coordinates on the page, and also renders a bitmap image of each page to support downstream operations. Then, the standard model pipeline applies a sequence of AI models independently on every page in the document to extract features and content, such as layout and table structures. Finally, the results from all pages are aggregated and passed through a post-processing stage, which augments metadata, detects the document language, infers reading-order and eventually assembles a typed document object which can be serialized to JSON or Markdown.\n",
      "\n",
      "## 3.1 PDF backends\n",
      "\n",
      "Two basic requirements to process PDF documents in our pipeline are a) to retrieve all text content and their geometric coordinates on each page and b) to render the visual representation of each page as it would appear in a PDF viewer. Both these requirements are encapsulated in Docling's PDF backend interface. While there are several open-source PDF parsing libraries available for python, we faced major obstacles with all of them for different reasons, among which were restrictive\n",
      "\n",
      "Figure 1: Sketch of Docling's default processing pipeline. The inner part of the model pipeline is easily customizable and extensible.\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "licensing (e.g. pymupdf [7]), poor speed or unrecoverable quality issues, such as merged text cells across far-apart text tokens or table columns (pypdfium, PyPDF) [15, 14].\n",
      "\n",
      "We therefore decided to provide multiple backend choices, and additionally open-source a custombuilt PDF parser, which is based on the low-level qpdf [4] library. It is made available in a separate package named docling-parse and powers the default PDF backend in Docling. As an alternative, we provide a PDF backend relying on pypdfium , which may be a safe backup choice in certain cases, e.g. if issues are seen with particular font encodings.\n",
      "\n",
      "## 3.2 AI models\n",
      "\n",
      "As part of Docling, we initially release two highly capable AI models to the open-source community, which have been developed and published recently by our team. The first model is a layout analysis model, an accurate object-detector for page elements [13]. The second model is TableFormer [12, 9], a state-of-the-art table structure recognition model. We provide the pre-trained weights (hosted on huggingface) and a separate package for the inference code as docling-ibm-models . Both models are also powering the open-access deepsearch-experience, our cloud-native service for knowledge exploration tasks.\n",
      "\n",
      "## Layout Analysis Model\n",
      "\n",
      "Our layout analysis model is an object-detector which predicts the bounding-boxes and classes of various elements on the image of a given page. Its architecture is derived from RT-DETR [16] and re-trained on DocLayNet [13], our popular human-annotated dataset for document-layout analysis, among other proprietary datasets. For inference, our implementation relies on the onnxruntime [5].\n",
      "\n",
      "The Docling pipeline feeds page images at 72 dpi resolution, which can be processed on a single CPU with sub-second latency. All predicted bounding-box proposals for document elements are post-processed to remove overlapping proposals based on confidence and size, and then intersected with the text tokens in the PDF to group them into meaningful and complete units such as paragraphs, section titles, list items, captions, figures or tables.\n",
      "\n",
      "## Table Structure Recognition\n",
      "\n",
      "The TableFormer model [12], first published in 2022 and since refined with a custom structure token language [9], is a vision-transformer model for table structure recovery. It can predict the logical row and column structure of a given table based on an input image, and determine which table cells belong to column headers, row headers or the table body. Compared to earlier approaches, TableFormer handles many characteristics of tables, such as partial or no borderlines, empty cells, rows or columns, cell spans and hierarchy both on column-heading or row-heading level, tables with inconsistent indentation or alignment and other complexities. For inference, our implementation relies on PyTorch [2].\n",
      "\n",
      "The Docling pipeline feeds all table objects detected in the layout analysis to the TableFormer model, by providing an image-crop of the table and the included text cells. TableFormer structure predictions are matched back to the PDF cells in post-processing to avoid expensive re-transcription text in the table image. Typical tables require between 2 and 6 seconds to be processed on a standard CPU, strongly depending on the amount of included table cells.\n",
      "\n",
      "## OCR\n",
      "\n",
      "Docling provides optional support for OCR, for example to cover scanned PDFs or content in bitmaps images embedded on a page. In our initial release, we rely on EasyOCR [1], a popular thirdparty OCR library with support for many languages. Docling, by default, feeds a high-resolution page image (216 dpi) to the OCR engine, to allow capturing small print detail in decent quality. While EasyOCR delivers reasonable transcription quality, we observe that it runs fairly slow on CPU (upwards of 30 seconds per page).\n",
      "\n",
      "We are actively seeking collaboration from the open-source community to extend Docling with additional OCR backends and speed improvements.\n",
      "\n",
      "## 3.3 Assembly\n",
      "\n",
      "In the final pipeline stage, Docling assembles all prediction results produced on each page into a well-defined datatype that encapsulates a converted document, as defined in the auxiliary package docling-core . The generated document object is passed through a post-processing model which leverages several algorithms to augment features, such as detection of the document language, correcting the reading order, matching figures with captions and labelling metadata such as title, authors and references. The final output can then be serialized to JSON or transformed into a Markdown representation at the users request.\n",
      "\n",
      "## 3.4 Extensibility\n",
      "\n",
      "Docling provides a straight-forward interface to extend its capabilities, namely the model pipeline. A model pipeline constitutes the central part in the processing, following initial document parsing and preceding output assembly, and can be fully customized by sub-classing from an abstract baseclass ( BaseModelPipeline ) or cloning the default model pipeline. This effectively allows to fully customize the chain of models, add or replace models, and introduce additional pipeline configuration parameters. To use a custom model pipeline, the custom pipeline class to instantiate can be provided as an argument to the main document conversion methods. We invite everyone in the community to propose additional or alternative models and improvements.\n",
      "\n",
      "Implementations of model classes must satisfy the python Callable interface. The \\_\\_call\\_\\_ method must accept an iterator over page objects, and produce another iterator over the page objects which were augmented with the additional features predicted by the model, by extending the provided PagePredictions data model accordingly.\n",
      "\n",
      "## 4 Performance\n",
      "\n",
      "In this section, we establish some reference numbers for the processing speed of Docling and the resource budget it requires. All tests in this section are run with default options on our standard test set distributed with Docling, which consists of three papers from arXiv and two IBM Redbooks, with a total of 225 pages. Measurements were taken using both available PDF backends on two different hardware systems: one MacBook Pro M3 Max, and one bare-metal server running Ubuntu 20.04 LTS on an Intel Xeon E5-2690 CPU. For reproducibility, we fixed the thread budget (through setting OMP NUM THREADS environment variable ) once to 4 (Docling default) and once to 16 (equal to full core count on the test hardware). All results are shown in Table 1.\n",
      "\n",
      "If you need to run Docling in very low-resource environments, please consider configuring the pypdfium backend. While it is faster and more memory efficient than the default docling-parse backend, it will come at the expense of worse quality results, especially in table structure recovery.\n",
      "\n",
      "Establishing GPU acceleration support for the AI models is currently work-in-progress and largely untested, but may work implicitly when CUDA is available and discovered by the onnxruntime and\n",
      "\n",
      "torch runtimes backing the Docling pipeline. We will deliver updates on this topic at in a future version of this report.\n",
      "\n",
      "Table 1: Runtime characteristics of Docling with the standard model pipeline and settings, on our test dataset of 225 pages, on two different systems. OCR is disabled. We show the time-to-solution (TTS), computed throughput in pages per second, and the peak memory used (resident set size) for both the Docling-native PDF backend and for the pypdfium backend, using 4 and 16 threads.\n",
      "\n",
      "| CPU                   | Thread budget   | native backend   | native backend   | native backend   | pypdfium backend   | pypdfium backend   | pypdfium backend   |\n",
      "|-----------------------|-----------------|------------------|------------------|------------------|--------------------|--------------------|--------------------|\n",
      "|                       | Thread budget   | TTS              | Pages/s          | Mem              | TTS                | Pages/s            | Mem                |\n",
      "| Apple M3 Max          | 4               | 177 s            | 1.27             | 6.20 GB          | 103 s              | 2.18               | 2.56 GB            |\n",
      "| (16 cores)            | 16              | 167 s            | 1.34             | 6.20 GB          | 92 s               | 2.45               | 2.56 GB            |\n",
      "| Intel(R) Xeon E5-2690 | 4 16            | 375 s 244 s      | 0.60 0.92        | 6.16 GB          | 239 s 143 s        | 0.94 1.57          | 2.42 GB            |\n",
      "\n",
      "## 5 Applications\n",
      "\n",
      "Thanks to the high-quality, richly structured document conversion achieved by Docling, its output qualifies for numerous downstream applications. For example, Docling can provide a base for detailed enterprise document search, passage retrieval or classification use-cases, or support knowledge extraction pipelines, allowing specific treatment of different structures in the document, such as tables, figures, section structure or references. For popular generative AI application patterns, such as retrieval-augmented generation (RAG), we provide quackling , an open-source package which capitalizes on Docling's feature-rich document output to enable document-native optimized vector embedding and chunking. It plugs in seamlessly with LLM frameworks such as LlamaIndex [8]. Since Docling is fast, stable and cheap to run, it also makes for an excellent choice to build document-derived datasets. With its powerful table structure recognition, it provides significant benefit to automated knowledge-base construction [11, 10]. Docling is also integrated within the open IBM data prep kit [6], which implements scalable data transforms to build large-scale multi-modal training datasets.\n",
      "\n",
      "## 6 Future work and contributions\n",
      "\n",
      "Docling is designed to allow easy extension of the model library and pipelines. In the future, we plan to extend Docling with several more models, such as a figure-classifier model, an equationrecognition model, a code-recognition model and more. This will help improve the quality of conversion for specific types of content, as well as augment extracted document metadata with additional information. Further investment into testing and optimizing GPU acceleration as well as improving the Docling-native PDF backend are on our roadmap, too.\n",
      "\n",
      "We encourage everyone to propose or implement additional features and models, and will gladly take your inputs and contributions under review . The codebase of Docling is open for use and contribution, under the MIT license agreement and in alignment with our contributing guidelines included in the Docling repository. If you use Docling in your projects, please consider citing this technical report.\n",
      "\n",
      "## References\n",
      "\n",
      "- [1] J. AI. Easyocr: Ready-to-use ocr with 80+ supported languages. https://github.com/ JaidedAI/EasyOCR , 2024. Version: 1.7.0.\n",
      "- [2] J. Ansel, E. Yang, H. He, N. Gimelshein, A. Jain, M. Voznesensky, B. Bao, P. Bell, D. Berard, E. Burovski, G. Chauhan, A. Chourdia, W. Constable, A. Desmaison, Z. DeVito, E. Ellison, W. Feng, J. Gong, M. Gschwind, B. Hirsh, S. Huang, K. Kalambarkar, L. Kirsch, M. Lazos, M. Lezcano, Y. Liang, J. Liang, Y. Lu, C. Luk, B. Maher, Y. Pan, C. Puhrsch, M. Reso, M. Saroufim, M. Y. Siraichi, H. Suk, M. Suo, P. Tillet, E. Wang, X. Wang, W. Wen, S. Zhang, X. Zhao, K. Zhou, R. Zou, A. Mathews, G. Chanan, P. Wu, and S. Chintala. Pytorch 2: Faster\n",
      "\n",
      "machine learning through dynamic python bytecode transformation and graph compilation. In Proceedings of the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2 (ASPLOS '24) . ACM, 4 2024. doi: 10.1145/3620665.3640366. URL https://pytorch.org/assets/pytorch2-2.pdf .\n",
      "\n",
      "- [3] C. Auer, M. Dolfi, A. Carvalho, C. B. Ramis, and P. W. Staar. Delivering document conversion as a cloud service with high throughput and responsiveness. In 2022 IEEE 15th International Conference on Cloud Computing (CLOUD) , pages 363-373. IEEE, 2022.\n",
      "- [4] J. Berkenbilt. Qpdf: A content-preserving pdf document transformer, 2024. URL https: //github.com/qpdf/qpdf .\n",
      "- [5] O. R. developers. Onnx runtime. https://onnxruntime.ai/ , 2024. Version: 1.18.1.\n",
      "- [6] IBM. Data Prep Kit: a community project to democratize and accelerate unstructured data preparation for LLM app developers, 2024. URL https://github.com/IBM/ data-prep-kit .\n",
      "- [7] A. S. Inc. PyMuPDF, 2024. URL https://github.com/pymupdf/PyMuPDF .\n",
      "- [8] J. Liu. LlamaIndex, 11 2022. URL https://github.com/jerryjliu/llama\\_index .\n",
      "- [9] M. Lysak, A. Nassar, N. Livathinos, C. Auer, and P. Staar. Optimized Table Tokenization for Table Structure Recognition. In Document Analysis and Recognition - ICDAR 2023: 17th International Conference, San Jos'e, CA, USA, August 21-26, 2023, Proceedings, Part II , pages 37-50, Berlin, Heidelberg, Aug. 2023. Springer-Verlag. ISBN 978-3-031-41678-1. doi: 10. 1007/978-3-031-41679-8 3. URL https://doi.org/10.1007/978-3-031-41679-8\\_3 .\n",
      "- [10] L. Mishra, S. Dhibi, Y. Kim, C. Berrospi Ramis, S. Gupta, M. Dolfi, and P. Staar. Statements: Universal information extraction from tables with large language models for ESG KPIs. In D. Stammbach, J. Ni, T. Schimanski, K. Dutia, A. Singh, J. Bingler, C. Christiaen, N. Kushwaha, V. Muccione, S. A. Vaghefi, and M. Leippold, editors, Proceedings of the 1st Workshop on Natural Language Processing Meets Climate Change (ClimateNLP 2024) , pages 193-214, Bangkok, Thailand, Aug. 2024. Association for Computational Linguistics. URL https://aclanthology.org/2024.climatenlp-1.15 .\n",
      "- [11] L. Morin, V. Weber, G. I. Meijer, F. Yu, and P. W. J. Staar. Patcid: an open-access dataset of chemical structures in patent documents. Nature Communications , 15(1):6532, August 2024. ISSN 2041-1723. doi: 10.1038/s41467-024-50779-y. URL https://doi.org/10.1038/ s41467-024-50779-y .\n",
      "- [12] A. Nassar, N. Livathinos, M. Lysak, and P. Staar. Tableformer: Table structure understanding with transformers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 4614-4623, 2022.\n",
      "- [13] B. Pfitzmann, C. Auer, M. Dolfi, A. S. Nassar, and P. Staar. Doclaynet: a large humanannotated dataset for document-layout segmentation. pages 3743-3751, 2022.\n",
      "- [14] pypdf Maintainers. pypdf: A Pure-Python PDF Library, 2024. URL https://github.com/ py-pdf/pypdf .\n",
      "- [15] P. Team. PyPDFium2: Python bindings for PDFium, 2024. URL https://github.com/ pypdfium2-team/pypdfium2 .\n",
      "- [16] Y. Zhao, W. Lv, S. Xu, J. Wei, G. Wang, Q. Dang, Y. Liu, and J. Chen. Detrs beat yolos on real-time object detection, 2023.\n",
      "\n",
      "## Appendix\n",
      "\n",
      "In this section, we illustrate a few examples of Docling' s output in Markdown and JSON.\n",
      "\n",
      "## DocLayNet: A Large Human-Annotated Dataset for Document-Layout Analysis\n",
      "\n",
      "Birgit Pfitzmann IBM Research Rueschlikon, Switzerland bpf@zurich.ibm.com\n",
      "\n",
      "Christoph Auer IBM Research Rueschlikon, Switzerland cau@zurich.ibm.com\n",
      "\n",
      "Michele Dolfi IBM Research Rueschlikon, Switzerland dol@zurich.ibm.com\n",
      "\n",
      "Ahmed S. Nassar IBM Research Rueschlikon, Switzerland ahn@zurich.ibm.com\n",
      "\n",
      "Peter Staar IBM Research Rueschlikon, Switzerland taa@zurich.ibm.com\n",
      "\n",
      "## ABSTRACT\n",
      "\n",
      "Accurate document layout analysis is a key requirement for highquality PDF document conversion. With the recent availability of public, large ground-truth datasets such as PubLayNet and DocBank, deep-learning models have proven to be very effective at layout detection and segmentation. While these datasets are of adequate size to train such models, they severely lack in layout variability since they are sourced from scientific article repositories such as PubMed and arXiv only. Consequently, the accuracy of the layout segmentation drops significantly when these models are applied on more challenging and diverse layouts. In this paper, we present $\\_{DocLayNet}$, a new, publicly available, document-layout annotation dataset in COCO format. It contains 80863 manually annotated pages from diverse data sources to represent a wide variability in layouts. For each PDF page, the layout annotations provide labelled bounding-boxes with a choice of 11 distinct classes. DocLayNet also provides a subset of double- and triple-annotated pages to determine the inter-annotator agreement. In multiple experiments, we provide baseline accuracy scores (in mAP) for a set of popular object detection models. We also demonstrate that these models fall approximately 10% behind the inter-annotator agreement. Furthermore, we provide evidence that DocLayNet is of sufficient size. Lastly, we compare models trained on PubLayNet, DocBank and DocLayNet, showing that layout predictions of the DocLayNettrained models are more robust and thus the preferred choice for general-purpose document-layout analysis.\n",
      "\n",
      "## CCS CONCEPTS\n",
      "\n",
      "· Information systems → Document structure ; · Applied computing → Document analysis ; · Computing methodologies → Machine learning ; Computer vision ; $\\_{Object detection}$;\n",
      "\n",
      "Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profi t or commercial advantage and that copies bear this notice and the full citation on thefirst page. Copyrights for third-party components of this work must be honored. For all other uses, contact the owner/author(s). KDD '22, August 14-18, 2022, Washington, DC, USA © 2022 Copyright held by the owner/author(s). ACM ISBN 978-1-4503-9385-0/22/08. https://doi.org/10.1145/3534678.3539043\n",
      "\n",
      "## DocLayNet: A Large Human-Annotated Dataset for Document-Layout Analysis\n",
      "\n",
      "Birgit Pfitzmann IBM Research Rueschlikon, Switzerland bpf@zurich.ibm.com\n",
      "\n",
      "Christoph Auer IBM Research Rueschlikon, Switzerland cau@zurich.ibm.com\n",
      "\n",
      "Michele Dolfi IBM Research Rueschlikon, Switzerland dol@zurich.ibm.com\n",
      "\n",
      "Ahmed S. Nassar IBM Research Rueschlikon, Switzerland ahn@zurich.ibm.com\n",
      "\n",
      "Peter Staar IBM Research Rueschlikon, Switzerland taa@zurich.ibm.com\n",
      "\n",
      "## ABSTRACT\n",
      "\n",
      "Accurate document layout analysis is a key requirement for highquality PDF document conversion. With the recent availability of public, large groundtruth datasets such as PubLayNet and DocBank, deep-learning models have proven to be very effective at layout detection and segmentation. While these datasets are of adequate size to train such models, they severely lack in layout variability since they are sourced from scientific article repositories such as PubMed and arXiv only. Consequently, the accuracy of the layout segmentation drops significantly when these models are applied on more challenging and diverse layouts. In this paper, we present DocLayNet , a new, publicly available, document-layout annotation dataset in COCO format. It contains 80863 manually annotated pages from diverse data sources to represent a wide variability in layouts. For each PDF page, the layout annotations provide labelled bounding-boxes with a choice of 11 distinct classes. DocLayNet also provides a subset of double- and triple-annotated pages to determine the inter-annotator agreement. In multiple experiments, we provide baseline accuracy scores (in mAP) for a set of popular object detection models. We also demonstrate that these models fall approximately 10% behind the inter-annotator agreement. Furthermore, we provide evidence that DocLayNet is of sufficient size. Lastly, we compare models trained on PubLayNet, DocBank and DocLayNet, showing that layout predictions of the DocLayNettrained models are more robust and thus the preferred choice for general-purpose document-layout analysis.\n",
      "\n",
      "## CCS CONCEPTS\n",
      "\n",
      "$\\_{· Information systems }$→$\\_{ Document structure ; · Applied computing }$ →$\\_{ Document analysis ; · Computing methodologies }$→$\\_{ Machine learning ;}$ Computer vision ; Object detection ;\n",
      "\n",
      "Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for third-party components of this work must be honored. For all other uses, contact the owner/author(s).\n",
      "\n",
      "KDD '22, August 14-18, 2022, Washington, DC, USA © 2022 Copyright held by the owner/author(s). ACM ISBN 978-1-4503-9385-0/22/08. https://doi.org/10.1145/3534678.3539043\n",
      "\n",
      "Figure 1: Four examples of complex page layouts across different document categories\n",
      "\n",
      "## KEYWORDS\n",
      "\n",
      "PDF document conversion, layout segmentation, object-detection, data set, Machine Learning\n",
      "\n",
      "## ACM Reference Format:\n",
      "\n",
      "Birgit Pfitzmann, Christoph Auer, Michele Dolfi, Ahmed S. Nassar, and Peter Staar. 2022. DocLayNet: A Large Human-Annotated Dataset for DocumentLayout Analysis. In Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD '22), August 14-18, 2022, Washington, DC, USA. ACM, New York, NY, USA, 9 pages. https://doi.org/10.1145/ 3534678.3539043\n",
      "\n",
      "Figure 1: Four examples of complex page layouts across different document categories\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "## KEYWORDS\n",
      "\n",
      "PDF document conversion, layout segmentation, object-detection, data set, Machine Learning\n",
      "\n",
      "## ACM Reference Format:\n",
      "\n",
      "Birgit Pfitzmann, Christoph Auer, Michele Dolfi , Ahmed S. Nassar, and Peter Staar. 2022. DocLayNet: A Large Human-Annotated Dataset for DocumentLayout Analysis. In Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD '22), August 14-18, 2022, Wash-$\\_{ington, DC, USA.}$ACM, New York, NY, USA, 9 pages. https://doi.org/10.1145/ 3534678.3539043\n",
      "\n",
      "1 INTRODUCTION\n",
      "\n",
      "Despite the substantial improvements achieved with machine-learning (ML) approaches and deep neural networks in recent years, document conversion remains a challenging problem, as demonstrated by the numerous public competitions held on this topic [1-4]. The challenge originates from the huge variability in PDF documents regarding layout, language and formats (scanned, programmatic or a combination of both). Engineering a single ML model that can be applied on all types of documents and provides high-quality layout segmentation remains to this day extremely challenging [5]. To highlight the variability in document layouts, we show a few example documents from the DocLayNet dataset in Figure 1. Figure 2: Title page of the DocLayNet paper (arxiv .org/pdf/2206.01062) - left PDF, right rendered Markdown. If recognized, metadata such as authors are appearing first under the title. Text content inside figures is currently dropped, the caption is retained and linked to the figure in the JSON representation (not shown).\n",
      "\n",
      "KDD '22, August 14-18, 2022, Washington, DC, USA Birgit Pfitzmann, Christoph Auer, Michele Dolfi, Ahmed S. Nassar, and Peter Staar\n",
      "\n",
      "Table 2: Prediction performance (mAP@0.5-0.95) of object detection networks on DocLayNet test set. The MRCNN (Mask R-CNN) and FRCNN (Faster R-CNN) models with ResNet-50 or ResNet-101 backbone were trained based on the network architectures from the detectron2 model zoo (Mask R-CNN R50, R101-FPN 3x, Faster R-CNN R101-FPN 3x), with default configurations. The YOLO implementation utilized was YOLOv5x6 [13]. All models were initialised using pre-trained weights from the COCO 2017 dataset.\n",
      "\n",
      "|                | human   | MRCNN   | MRCNN   | FRCNN   | YOLO   |\n",
      "|----------------|---------|---------|---------|---------|--------|\n",
      "|                | human   | R50     | R101    | R101    | v5x6   |\n",
      "| Caption        | 84-89   | 68.4    | 71.5    | 70.1    | 77.7   |\n",
      "| Footnote       | 83-91   | 70.9    | 71.8    | 73.7    | 77.2   |\n",
      "| Formula        | 83-85   | 60.1    | 63.4    | 63.5    | 66.2   |\n",
      "| List-item      | 87-88   | 81.2    | 80.8    | 81.0    | 86.2   |\n",
      "| Page-footer    | 93-94   | 61.6    | 59.3    | 58.9    | 61.1   |\n",
      "| Page-header    | 85-89   | 71.9    | 70.0    | 72.0    | 67.9   |\n",
      "| Picture        | 69-71   | 71.7    | 72.7    |         | 77.1   |\n",
      "| Section-header | 83-84   | 67.6    | 69.3    | 68.4    | 74.6   |\n",
      "| Table          | 77-81   | 82.2    | 82.9    | 82.2    | 86.3   |\n",
      "| Text           | 84-86   | 84.6    | 85.8    | 85.4    |        |\n",
      "|                |         | 76.7    | 80.4    | 79.9    | 88.1   |\n",
      "| Title          | 60-72   |         |         |         | 82.7   |\n",
      "| All            | 82-83   | 72.4    | 73.5    | 73.4    | 76.8   |\n",
      "\n",
      "to avoid this at any cost in order to have clear, unbiased baseline numbers for human document-layout annotation. Third, we introduced the feature of snapping boxes around text segments to obtain a pixel-accurate annotation and again reduce time and effort. The CCS annotation tool automatically shrinks every user-drawn box to the minimum bounding-box around the enclosed text-cells for all purely text-based segments, which excludes only Table and $\\_{Picture}$. For the latter, we instructed annotation staffto minimise inclusion of surrounding whitespace while including all graphical lines. A downside of snapping boxes to enclosed text cells is that some wrongly parsed PDF pages cannot be annotated correctly and need to be skipped. Fourth, we established a way toflag pages as rejected for cases where no valid annotation according to the label guidelines could be achieved. Example cases for this would be PDF pages that render incorrectly or contain layouts that are impossible to capture with non-overlapping rectangles. Such rejected pages are not contained in thefinal dataset. With all these measures in place, experienced annotation staffmanaged to annotate a single page in a typical timeframe of 20s to 60s, depending on its complexity.\n",
      "\n",
      "## 5 EXPERIMENTS\n",
      "\n",
      "The primary goal of DocLayNet is to obtain high-quality ML models capable of accurate document-layout analysis on a wide variety of challenging layouts. As discussed in Section 2, object detection models are currently the easiest to use, due to the standardisation of ground-truth data in COCO format [16] and the availability of general frameworks such as detectron2 [17]. Furthermore, baseline numbers in PubLayNet and DocBank were obtained using standard object detection models such as Mask R-CNN and Faster R-CNN. As such, we will relate to these object detection methods in this\n",
      "\n",
      "Figure 3: Page 6 of the DocLayNet paper. If recognized, metadata such as authors are appearing first under the title. Elements recognized as page headers or footers are suppressed in Markdown to deliver uninterrupted content in reading order. Tables are inserted in reading order. The paragraph in \"5. Experiments\" wrapping over the column end is broken up in two and interrupted by the table.\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "Figure 5: Prediction performance (mAP@0.5-0.95) of a Mask R-CNN network with ResNet50 backbone trained on increasing fractions of the DocLayNet dataset. The learning curv eflattens around the 80% mark, indicating that increasing the size of the DocLayNet dataset with similar data will not yield significantly better predictions.\n",
      "\n",
      "paper and leave the detailed evaluation of more recent methods mentioned in Section 2 for future work.\n",
      "\n",
      "In this section, we will present several aspects related to the performance of object detection models on DocLayNet. Similarly as in PubLayNet, we will evaluate the quality of their predictions using mean average precision (mAP) with 10 overlaps that range from 0.5 to 0.95 in steps of 0.05 (mAP@0.5-0.95). These scores are computed by leveraging the evaluation code provided by the COCO API [16].\n",
      "\n",
      "## Baselines for Object Detection\n",
      "\n",
      "In Table 2, we present baseline experiments (given in mAP) on Mask R-CNN [12], Faster R-CNN [11], and YOLOv5 [13]. Both training and evaluation were performed on RGB images with dimensions of $^{1025}$×1025 pixels. For training, we only used one annotation in case of redundantly annotated pages. As one can observe, the variation in mAP between the models is rather low, but overall between 6 and 10% lower than the mAP computed from the pairwise human annotations on triple-annotated pages. This gives a good indication that the DocLayNet dataset poses a worthwhile challenge for the research community to close the gap between human recognition and ML approaches. It is interesting to see that Mask R-CNN and Faster R-CNN produce very comparable mAP scores, indicating that pixel-based image segmentation derived from bounding-boxes does not help to obtain better predictions. On the other hand, the more recent Yolov5x model does very well and even out-performs humans on selected labels such as $\\_{Text}$, Table and $\\_{Picture}$. This is not entirely surprising, as and Picture are abundant and the most visually distinctive in a document.\n",
      "\n",
      "Prediclion Derormance (ip80.5-0.85 ohobeci detecion Lalo ks Doclaynal Lest saL Ine VACNN (Mask R-CNNI and FACNN (Faster A-CNM) mcdcs mith PosNc: 50 PosNo: 101 backtone woro trainod based on Enc nchwwcrk achrocturos tom Ihc Oeronhroase a-CNn aso rioi-Fpn 3x, FasieA-Cnn a1o1-FPN Jx), wilh delaui conlwuralions The Yolg mpomorcabon utilzod was YoloSyb(13| modos woro inbalsod usino cro-trunodmonhts Iron Coco 2017 datasot\n",
      "\n",
      "|            | noun   | Mrcnn   | MaCNN   | Frcne   | Yola   |\n",
      "|------------|--------|---------|---------|---------|--------|\n",
      "| Gaoon      |        |         |         |         |        |\n",
      "| Foomole    |        |         |         |         |        |\n",
      "| Foula      |        |         |         |         |        |\n",
      "| Ust-lern   |        |         |         |         |        |\n",
      "| Page-locer |        |         |         |         |        |\n",
      "| Paqe-haoe  |        |         |         |         |        |\n",
      "| Pxlu       |        |         |         |         |        |\n",
      "| Sonhoade   |        |         |         |         |        |\n",
      "\n",
      "iD avodIhbs arcost cha unbasndbasolino numoc human cocumnnt-Laycut annotalion; Thrd Inirooucod leatura 0i snapoina Doxes around leul scainunis cblan & pixel-accutale annolaton and aJan feduce lifre and elonThe CCS annoinbon aloMala shruks Ovory Usor-drawnboro mnmum coundino-borarounaIho onclosod coxt-colls Purolytort basud scoitontwhich uxclldcs Ort Tatlo and Picluo latsor inssucicdannjlabon shu mnim so inclusion Suitcurding mlospeco whloIncvon Oenoncang doans d0 oisnaocmnbors Onchseo Ihal So10 wioogly Paisoc Pogcs cannol be annotalcd coTcCEY and nccd Supood Foudtn Oshdned Wuyio(ao Dagcs (ccclod Cascs whcion valid anncuabon eccofding abeiqu Oelines coukbe acheneu Eamnole Case, fliswouk PDF peoe3 Ihal rendernnccrrecUy contanlavouts hat Imnosshk cantro mith Vananonnyogannio{ Suchiceciodoaoos not coralnon Ihofnn Ihe Auroknacoarroehetye annolauco slall Munuoud unnoln sina \" Puou lypical Lmetamre 0l 20s 10 605 cecendng conoanty\n",
      "\n",
      "## 5 EXPERIMENTS\n",
      "\n",
      "Ine crimary goal DochayNor cblan hion-quality Modols AccuaiodoaMoiuvana as WMevanalon chalcnonglayoul: Cecurdg echon Doicdi Delccion modcbs rtenl Casistlo Usc, Quulo Ghuodnduhon ground-vuth data COCO lornat [16] anxd avalaoily enetal Irarne nOiks uch derectrcnzn7] Furnemmore, baseline nmnoe < I Putun: Notand DocBank calanodusnsuandad coict dosnchonmodols such Mas< A CNN and Fasior A CNn Suan blramhdelecha nonInn Canacle\n",
      "\n",
      "Faur Prco chon ocrlonanC( 005-095) ola Mask A-CNN ncthoik ilh AcsNciSo backtono brainod on incrcasing Iracbons oi DocLaynei calasot Tne loannp auro altons around Ih0 €03 noicahino Ihal inxreasing /e 520 Q Iho DocLøy Nel dalasot Amardaen nol Yicid sn: dcrOocC Chons AA\n",
      "\n",
      "pangrandloave detallod evalvallon %moro rcoarimolhods monionon Secilg Jorhlure work\n",
      "\n",
      "Inuhs sechon All Deseni seur8/ asoecis relas00 Perormane ouieci celecon DoxclayNet Simamtas In PLoLaytnt oynuato Inn qualmy cuthnlr crodictionsusiramnanavnna prncisicn (TTAP) wch Iovrdaos that rango trom 0 5ta 005 (nap,o6-00: Me onue Fnoulay Croluoik uvalaion coou piayIed DY Ihu COCO AFI /161 ook\n",
      "\n",
      "## Baselines for Object Detection\n",
      "\n",
      "ptesenl baselne expenrnenls (Ovenin MAF) on Mass R-CNN /121 Fasler F-CNN [11] a1 YOLOvS [13] Bou1 brann aniavailang woropomormon AGa Imnops vith dimonsions 1025 chxrols For tralring onN usodomnannolatln Incaso ohcuunourfhunnolulco Dlac3 Ohaen Vuruhoninaptalunhemagny usnaroA en hn 10?7 lovorrnannomap conoutec paicaisehuman anncrbons Aoo-amculeopnnos Ins Cves nocation Ihatiho DocLayNot daasci DO5o s mornwro claignoo [csoarcncamurt gap bcthoon human focogniticn and VL aporoaces nlelesuino IharNaskR-CNNead Fasler GNincroovo cmnanen Maseoes nnocauna Ulbi AICBasodnanc scomorubon oormvod Irom bounon)ooros Ooo{ abuin totcrorcocbons Ontho chornnno Mcroicconi YolavSrmrodel does verywell und even Dul-Perdorins selectedlubels such Tedle undpcturl enbeh surcrisio Ta oloandPchre Aoincant Animemostusialhcishinsne documen: Oun hunne\n",
      "\n",
      "KDD '22, August 14-18, 2022, Washington, DC, USA Birgit Pfitzmann, Christoph Auer, Michele Dolfi, Ahmed S. Nassar, and Peter Staar\n",
      "\n",
      "Table 1: DocLayNet dataset overview. Along with the frequency of each class label, we present the relative occurrence (as % of row \"Total\") in the train, test and validation sets. The inter-annotator agreement is computed as the mAP@0.5-0.95 metric between pairwise annotations from the tripleannotated pages, from which we obtain accuracy ranges. Table 1: DocLayNet dataset overview. Along with the frequency of each class label, we present the relative occurr ence (as % of row \"Total\") in the train, test and validation sets. The inter-annotator agreement is computed as the mAP@0.5-0.95 metric between pairwise annotations from the triple-annotated pages, from which we obtain accuracy ranges. B\n",
      "\n",
      "|                | Count   | % of Total   | % of Total   | % of Total   | triple inter-annotator mAP @ 0.5-0.95 (%)   | triple inter-annotator mAP @ 0.5-0.95 (%)   | triple inter-annotator mAP @ 0.5-0.95 (%)   | triple inter-annotator mAP @ 0.5-0.95 (%)   | triple inter-annotator mAP @ 0.5-0.95 (%)   | triple inter-annotator mAP @ 0.5-0.95 (%)   | triple inter-annotator mAP @ 0.5-0.95 (%)   |\n",
      "|----------------|---------|--------------|--------------|--------------|---------------------------------------------|---------------------------------------------|---------------------------------------------|---------------------------------------------|---------------------------------------------|---------------------------------------------|---------------------------------------------|\n",
      "| class label    |         | Train        | Test         | Val          | All                                         | Fin                                         | Man                                         | Sci                                         | Law                                         | Pat                                         | T en                                        |\n",
      "| Caption        | 22524   | 2.04         | 1.77         | 2.32         | 84-89                                       | 40-61                                       | 86-92                                       | 94-99                                       | 95-99                                       | 69-78                                       | n/a                                         |\n",
      "| Footnote       | 6318    | 0.60         | 0.31         | 0.58         | 83-91                                       | n/a                                         | 100                                         | 62-88                                       | 85-94                                       | n/a                                         | 82-97                                       |\n",
      "| Formula        | 25027   | 2.25         | 1.90         | 2.96         | 83-85                                       |                                             | n/a                                         | 84-87                                       | 86-96                                       |                                             | n/a                                         |\n",
      "| List-item      | 185660  | 17.19        | 13.34        | 15.82        | 87-88                                       | 74-83                                       | 90-92                                       | 97-97                                       | 81-85                                       | 75-88                                       | 93-95                                       |\n",
      "| Page-footer    | 70878   | 6.51         | 5.58         | 6.00         | 93-94                                       | 88-90                                       | 95-96                                       | 100                                         | 92-97                                       | 100                                         | 96-98                                       |\n",
      "| Page-header    | 58022   | 5.10         | 6.70         | 5.06         | 85-89                                       | 66-76                                       | 90-94                                       | 98-100                                      | 91-92                                       | 97-99                                       | 81-86                                       |\n",
      "| Picture        | 45976   | 4.21         | 2.78         | 5.31         | 69-71                                       | 56-59                                       | 82-86                                       | 69-82                                       | 80-95                                       | 66-71                                       | 59-76                                       |\n",
      "| Section-header | 142884  | 12.60        | 15.77        | 12.85        | 83-84                                       | 76-81                                       | 90-92                                       | 94-95                                       | 87-94                                       | 69-73                                       | 78-86                                       |\n",
      "| Table          | 34733   | 3.20         | 2.27         | 3.60         | 77-81                                       | 75-80                                       | 83-86                                       | 98-99                                       | 58-80                                       | 79-84                                       | 70-85                                       |\n",
      "| Text           | 510377  | 45.82        | 49.28        | 45.00        | 84-86                                       | 81-86                                       | 88-93                                       | 89-93                                       | 87-92                                       | 71-79                                       | 87-95                                       |\n",
      "| Title          | 5071    | 0.47         | 0.30         | 0.50         | 60-72                                       | 24-63                                       | 50-63                                       | 94-100                                      | 82-96                                       | 68-79                                       | 24-56                                       |\n",
      "| Total          | 1107470 | 941123       | 99816        | 66531        | 82-83                                       | 71-74                                       | 79-81                                       | 89-94                                       | 86-91                                       | 71-76                                       | 68-85                                       |\n",
      "\n",
      "Figure 3: face. The laid te be drawn the respe\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "we distribute d the annotation workload and performed continuous quality contr ols. Phase one and two required a small team of experts only. For phases three and four, a group of 40 dedicated annotators were assembled and supervised. Phase 1: Data selection and preparation. Our inclusion cri-\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "of pages ed by seerties. For cument figur es or object how\n",
      "\n",
      "d the colfealayout labels. Pageand $\\_{Title}$. class cificity ed for of the ambiguous, while coverage ensures that all meaningful items on a page can be annotated. We refrained from class labels that are very specific to a document category, such as Abstract in the Scientific Articles category. We also avoided class labels that are tightly linked to the semantics of the text. Labels such as Author and $\\_{Affiliation}$, as seen\n",
      "\n",
      "teria for documents were described in Section 3. A large effort went into ensuring that all documents are free to use. The data sources in DocBank, are often only distinguishable by discriminating on $^{3}$https://arxiv.org/ Figure 4: Table 1 from the DocLayNet paper in the original PDF (A), as rendered Markdown (B) and in JSON representation (C). Spanning table cells, such as the multi-column header \"triple interannotator mAP@0.5-0.95 (%)\", is repeated for each column in the Markdown representation (B), which guarantees that every data point can be traced back to row and column headings only by its grid coordinates in the table. In the JSON representation, the span information is reflected in the fields of each table cell (C).\n"
     ]
    }
   ],
   "source": [
    "from docling.document_converter import DocumentConverter\n",
    "\n",
    "source = \"https://arxiv.org/pdf/2408.09869\"  # document per local path or URL\n",
    "converter = DocumentConverter()\n",
    "result = converter.convert(source)\n",
    "print(result.document.export_to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF downloaded successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 9 files: 100%|██████████| 9/9 [00:00<00:00, 9007.10it/s]\n",
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Can't instantiate abstract class BaseChunker with abstract method chunk",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m conv_res \u001b[38;5;241m=\u001b[39m DocumentConverter()\u001b[38;5;241m.\u001b[39mconvert(local_pdf_path)\n\u001b[0;32m     21\u001b[0m doc \u001b[38;5;241m=\u001b[39m conv_res\u001b[38;5;241m.\u001b[39mdocument\n\u001b[1;32m---> 22\u001b[0m chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[43mBaseChunker\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mchunk(doc))\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(chunks[\u001b[38;5;241m30\u001b[39m])\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(chunks))\n",
      "\u001b[1;31mTypeError\u001b[0m: Can't instantiate abstract class BaseChunker with abstract method chunk"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from docling.document_converter import DocumentConverter\n",
    "from docling_core.transforms.chunker import BaseChunker\n",
    "\n",
    "\n",
    "\n",
    "# Step 1: Download the PDF\n",
    "url = \"https://investors.portillos.com/node/8466/pdf\"\n",
    "local_pdf_path = \"document.pdf\"\n",
    "\n",
    "response = requests.get(url)\n",
    "if response.status_code == 200:\n",
    "    with open(local_pdf_path, \"wb\") as file:\n",
    "        file.write(response.content)\n",
    "    print(\"PDF downloaded successfully.\")\n",
    "else:\n",
    "    print(f\"Failed to download PDF. Status code: {response.status_code}\")\n",
    "\n",
    "\n",
    "conv_res = DocumentConverter().convert(local_pdf_path)\n",
    "doc = conv_res.document\n",
    "chunks = list(BaseChunker().chunk(doc))\n",
    "\n",
    "print(chunks[30])\n",
    "print(len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://investors.portillos.com/node/8466/pdf\n",
      "https://corporate.mcdonalds.com/content/dam/sites/corp/nfl/pdf/2023%20Annual%20Report_vf.pdf\n",
      "https://s23.q4cdn.com/574569502/files/doc_financials/2023/ar/salesforce-fy-2023-annual-report.pdf\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def google_search(query):\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "    }\n",
    "    url = f'https://www.google.com/search?q={query}'\n",
    "    response = requests.get(url, headers=headers)\n",
    "    return response.text\n",
    "\n",
    "def extract_pdf_url(html):\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    links = soup.find_all('a', href=True)\n",
    "    for link in links:\n",
    "        url = link['href']\n",
    "        if url[-3:] == 'pdf':\n",
    "            return url\n",
    "    return None\n",
    "\n",
    "# Perform Google search and extract PDF link\n",
    "html = google_search('Portillo\\'s annual report 2023 filetype:pdf')\n",
    "pdf_url = extract_pdf_url(html)\n",
    "print(pdf_url)\n",
    "\n",
    "html = google_search('McDonald\\'s annual report 2023 filetype:pdf')\n",
    "pdf_url = extract_pdf_url(html)\n",
    "print(pdf_url)\n",
    "\n",
    "html = google_search('Salesforce annual report 2023 filetype:pdf')\n",
    "pdf_url = extract_pdf_url(html)\n",
    "print(pdf_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operator: Good day, and welcome to the Apple Q4 Fiscal Year 2023 Earnings Conference Call. Today's call is being recorded. At this time, for opening remarks and introductions, I would like to turn the call over to Suhasini Chandramouli, Director of Investor Relations. Please go ahead.\n",
      "Suhasini Chandramouli: Thank you. Good afternoon, and thank you for joining us. Speaking first today is Apple's CEO, Tim Cook. And he'll be followed by CFO, Luca Maestri. After that, we'll open the call to questions from analysts. Please note that some of the information you'll hear during our discussion today will consist of forward-looking statements, including without limitation, those regarding revenue, gross margin, operating expenses, other income and expense, taxes, capital allocation and future business outlook, including the potential impact of macroeconomic conditions on the company's business and results of operations. These statements involve risks and uncertainties that may cause actual results or trends to differ materially from our forecast. For more information, please refer to the risk factors discussed in Apple's most recently filed annual report on Form 10-K and the Form 8-K filed with the SEC today along with the associated press release. Apple assumes no obligation to update any forward-looking statements, which speak only as of the date they are made. I'd now like to turn the call over to Tim for introductory remarks.\n",
      "Tim Cook: Thank you, Suhasini. Good afternoon, everyone, and thanks for joining the call. Today, Apple is reporting revenue of $89.5 billion for the September quarter. We achieved an all-time revenue record in India, as well as September quarter records in several countries, including Brazil, Canada, France, Indonesia, Mexico, the Philippines, Saudi Arabia, Turkey, the UAE, Vietnam and more. iPhone revenue came in ahead of our expectations, setting a September quarter record, as well as quarterly records in many markets, including China mainland, Latin America, the Middle-East, South Asia and an all-time record in India. In services, we set an all-time revenue record with double-digit growth and ahead of our expectations. During the September quarter, we continue to face an uneven macroeconomic environment, including foreign exchange headwinds and we've navigated these challenges by following the same principles that have always guided us. We've continued to invest in the future and manage for the long-term. We've adapted continuously to circumstances beyond our control, while being thoughtful and deliberate on spending. And we've carved a path of groundbreaking innovations and delivered with excellence every step of the way. That includes Apple Vision Pro, which has gotten such an amazing response from developers who are currently creating truly incredible apps. We're excited to get this magical product in the hands of customers early next year. Now let me share more about our products, beginning with iPhone. iPhone revenue came in at $43.8 billion, 3% higher than a year ago, and a new record for the September quarter. This fall, we were thrilled to debut the iPhone 15 lineup. The all-new iPhone 15 and iPhone 15 Plus feature a gorgeous design, powerful cameras and the intuitive Dynamic Island. Powered by the industry-leading A17 Pro, our iPhone15 Pro lineup has a beautiful strong and durable titanium design and the best iPhone camera system ever, including a 5X Telephoto lens on iPhone 15 Pro Max. Customers are loving the entire iPhone 15 family and reviews have been off the charts. In Mac, revenue came in at $7.6 billion, down 34% year-over-year from the prior year's record quarter. This was due to challenging market conditions, as well as difficult compares against the supply disruptions and subsequent demand recapture we experienced a year ago. Earlier this week, we were excited to unveil the next generation of Apple silicon with our incredible family of M3 chips, M3; M3 Pro; and M3 Max. We're continuing to innovate at a tremendous pace. And our industry-leading lineup of personal computers just got even better. The new MacBook Pro lineup brings our most advanced technology to our Pro users, while iMac, the world's best-selling all-in-one, just got faster and more capable. And according to the latest data from Student Monitor, nearly two out of three college students chose a Mac. We couldn't be more excited about the future. Turning to iPad. Revenue for the September quarter was $6.4 billion. iPad sets the gold standard for tablets and our competitors are unable to match the iPad experience that is enabled by our seamless integration of hardware and software. iPad is also our most versatile product. In classrooms around the world, it's helping educators bring lessons to life, while giving students a window into the world around them. And in artist workshops, design studios and everywhere else, creative minds come together, iPad supercharges the creative process, helping users take their ideas farther than they ever could before. Across wearables, home and accessories, revenue came in at $9.3 billion. Apple Watch has become essential in our lives and this is our best Apple Watch lineup ever. With Apple Watch Series 9 and Apple Watch Ultra 2, we're giving people even more tools to stay safe and live healthy, active lives. With the new double tap gesture, users can easily control Apple Watch Series 9 and Apple Watch Ultra 2 using just one hand and without touching the display. It feels like magic. Our latest Apple Watch lineup also includes our first-ever carbon-neutral products, a significant achievement of innovation and determination. Apple's unique ecosystem of hardware, software, and services delivers an unparalleled user experience. During the quarter, we also had the chance to introduce a range of exciting new updates to our software that will allow users to get even more out of their devices. Whether it's personalized contact posters and new face time features in iOS 17, new tools for users to make their experience their own in macOS Sonoma and iPadOS 17, or a bold new look in watchOS 10 that lets you see and do more, faster than ever, Apple is delivering an even better, richer experience that users are loving. Services revenue set an all-time record of $22.3 billion, a 16% year-over-year increase. We achieved all-time revenue records across App Store, advertising, AppleCare, iCloud, payment services, and video, as well as the September quarter revenue record in Apple Music. Whether subscribers are waking up to headlines on Apple News+, getting their morning workout in with Fitness+, feeling the beat with Apple Music on their way to work or school, or unwinding at the end of the day with Apple Arcade, we have so many different services to enrich their day. Apple TV+ continues to delight customers as well, with new and returning shows like the Morning Show, Lessons in Chemistry and Monarch. We're telling impactful stories that inspire imagination and stir the soul. Making movies that make a difference is also at the heart of Apple TV+ and we were thrilled to produce Martin Scorsese's Killers of the Flower Moon, a powerful work of cinema that premiered in theaters around the world last month. We're proud to say that since launch, just over four years ago, Apple TV+ has earned nearly 1,600 award nominations and nearly 400 wins. We also offer subscribers an unprecedented live sports experience with MLS Season Pass. We couldn't be more pleased with how our partnership with Major League Soccer has gone in its first year. Subscriptions to MLS Season Pass have exceeded our expectations and we're excited to continue that momentum next year. With the playoffs now underway, we can't wait to see who takes home MLS cup. And nowhere does the magic of Apple come alive more than it does in our stores. Over the past year, we've continued to find ways to connect with even more customers. We welcomed customers to our first-ever retail locations in India. We also opened doors to new stores in Korea, China and the UK and expanded the Apple store online to Vietnam and Chile. And we have another store opening in China this week. In September, I joined our team at Apple Fifth Avenue on launch day and the energy and excitement were unbelievable. Every time we connect with the customer, we're reminded why we do what we do. From simple joys of creating and sharing memories, to lifesaving features like emergency SoS via satellite, we're enriching lives in ways large and small. And whether we're working to safeguard user privacy, ensure technology made by Apple is accessible for everyone, or build an even more inclusive workplace, we're determined to lead with our values. Our environmental efforts are a great example of the intersection of our work and our values. Across Apple, we act on a simple premise, the best products in the world should be the best products for the world. We've made our environmental work a central focus of our innovation, because we feel a responsibility to leave the world better than we found it and because we know that climate change cannot be stopped, unless everyone steps up and does their part. Our first ever carbon-neutral products represent a major milestone and we're going to go even further. We plan to make every product across our lineup carbon neutral by the end of the decade. And we're not doing it alone. Over 300 of our suppliers have committed to using a 100% clean energy for Apple production by 2030. We also continue to invest in entrepreneurs who are lighting the way for a greener, more equitable future. Through our third impact accelerator class, we're proud to support a new class of diverse innovators on the cutting edge of green technology and clean energy. Apple is always looking forward, driven in equal measure by a sense a possibility and a deep belief in our purpose. We're motivated by the meaningful difference we can make for our customers and keenly determined to push the limits of technology even further. And that's why I'm so confident that Apple's future is bright. With that, I'll turn it over to Luca.\n",
      "Luca Maestri: Thank you, Tim, and good afternoon, everyone. Revenue for the September quarter was $89.5 billion, down less than 1% from last year. Foreign exchange had a negative impact of over 2 percentage points. And on a constant-currency basis, our revenue grew year-over-year in total, and in each geographic segment. We set a September quarter record in the Americas and saw strong performance across our emerging markets, where both iPhone and Services grew double digits. Products revenue was $67.2 billion, down 5% from last year, due to very challenging compares on both Mac and iPad, which I will discuss in more detail later on. At the same time, we reached a September quarter record on iPhone, driven by strength in emerging markets. Our total installed-base of active devices reached an all-time high across all products and all geographic segments, thanks to our high levels of customer satisfaction and many new customers joining our ecosystem. Our Services revenue set an all-time record of $22.3 billion, up 16% year-over-year, with growth accelerating sequentially from the June quarter. Our performance in Services were broad based, as we reached all-time revenue records in the Americas, Europe and rest of Asia-Pacific and a September quarter record in Greater China. We also set new records in every Services category. Company gross margin set a September quarter record at 45.2%, up 70 basis points sequentially, driven by leverage and favorable mix, partially offset by foreign exchange. Products gross margin was 36.6%, up 120 basis points sequentially, also driven by leverage and mix, partially offset by foreign exchange. Services gross margin was 70.9%, up 40 basis points from last quarter due to a different mix. Operating expenses of $13.5 billion were at the low end of the guidance range we provided, up 2% year-over-year. Net income was $23 billion, diluted earnings per share was $1.46, up 13% versus last year and a September quarter record, and operating cash flow was strong at $21.6 billion. Let me now provide more detail for each of our revenue categories. iPhone revenue was $43.8 billion, up 3% year-over-year and a new September quarter record. We had strong performance in several markets, including an all-time record in India as September quarter records in Canada, Latin America, the Middle East, and South Asia . Our iPhone active installed base grew to a new all-time high and fiscal 2023 was another record year for switches. We continue to see extremely high levels of customer satisfaction which 451 Research recently measured at 98% in the U.S. Mac revenue was $7.6 billion, down 34% year-over-year, driven by challenging market conditions and compounded by a difficult compare in our own business, whereby last year we experienced supply disruptions from factory shutdowns in the June quarter and were subsequently able to fulfill significant pent-up demand during the September quarter. We also had a difference in launch timing with the MacBook Air launching earlier this year in the June quarter compared to the September quarter last year. We have great confidence in our Mac lineup and are excited about the recently announced iMac and MacBook Pro powered by our M3 chips. Our installed base is at an all-time high and half of Mac buyers during the quarter were new to the product, driven by MacBook Air. Also, we saw reported customer satisfaction of 97% for Mac in the U.S. iPad generated $6.4 billion in revenue, down 10% year-over-year. Similar to Mac, these results were a function of a difficult compare from the supply disruptions in the June quarter a year ago and the subsequent fulfillment of pent-up demand in the September quarter. iPad continues to attract a large number of new customers to the installed base with over half of the customers who purchase iPads during the quarter being new to the product and the latest reports from 451 Research indicate customer satisfaction of 98% in the U.S. Wearables, Home and Accessories revenue was $9.3 billion, down 3% year-over-year. We had a September quarter record in Europe and we saw strong performance in several emerging markets around the world. Apple Watch continues to expand its reach with nearly two-thirds of customers purchasing Apple Watch during the quarter being new to the product and customer satisfaction for the Watch was recently measured at 97% in the U.S. Services had a great quarter. We reached a new all-time revenue record of $22.3 billion, up 16% year-over-year. And we're happy to see growth coming from all categories and every geographic segment, which is a direct result of the strength of our ecosystem. Our installed base of over 2 billion active devices continues to grow at a nice pace and establishes a solid foundation for the future expansion of the ecosystem. And we continue to see increased customer engagement with our Services. Both transacting accounts and paid accounts grew double-digits year-over-year, each reaching a new all-time high. Also our paid subscriptions showed strong growth. We have well over 1 billion paid subscriptions across the services on our platform, nearly double the number we had only three years ago. And finally, we continue to improve the breadth and quality of our current services from exciting new content on Apple TV+ and Apple Arcade to additional storage tiers on iCloud. We believe our customers will love this new offering. Turning to enterprise. We are excited to see our business customers in both developed and emerging markets expand their deployment of Apple products and technologies to drive business innovation and employee satisfaction. Starbucks continuously invest in Apple technology to bring the best experience to the customers and employees, including tens of thousands of iPads across all retail stores to help their teams streamline order management, operations and training. In addition, Starbucks recently refreshed over 10,000 Macs to the latest M2-powered MacBook Air for all store managers, enabling them to do their best work and improve productivity. And in Indonesia, popular technology company GoTo is offering Mac as a choice, so that employees can have the best tools to be most productive. Today, more than half of its workforce are already choosing Mac for work. Let me now turn to our cash position and capital return program. We ended the quarter with over $162 billion in cash and marketable securities. We increased commercial paper by $2 billion, leaving us with total debt of $111 billion. As a result, net cash was $51 billion at the end of the quarter. And our goal of becoming net cash-neutral over time remains unchanged. During the quarter, we returned nearly $25 billion to shareholders, including $3.8 billion in dividends and equivalents and $15.5 billion through open market repurchases of 85 million Apple shares. We also began a $5 billion accelerated share repurchase program in August, resulting in the initial delivery and retirement of 22 million shares. Taking a step back, as we close our 2023 fiscal year, our annual revenue was $383 billion. While it was down 3% from the prior year, it grew on a constant-currency basis despite the volatile and uneven macroeconomic environment. Our year-over-year revenue performance improved each quarter as we went through the year, and so did our earnings per share performance, as we reported double-digit EPS growth in the September quarter. We are particularly pleased with our performance in emerging markets with revenue reaching an all-time record in fiscal 2023 and double-digit growth in constant currency. We are expanding our direct presence in these markets from new Apple retail stores in India to online stores in Vietnam and Chile. And we continue to work with our partners to offer a wide range of affordability programs so that we can best serve our customers. We're very excited about the momentum we have in these markets and the opportunity ahead of us. As we move ahead into the December quarter, I'd like to review our outlook, which includes the types of forward-looking information that Suhasini referred to at the beginning of the call. The color we are providing today assumes that the macroeconomic outlook doesn't worsen from what we are projecting today for the current quarter. Also, on foreign exchange, we expect a negative year-over-year revenue impact of about 1 percentage point. As a reminder, the December quarter this year will last the usual 13 weeks, whereas the December quarter a year ago spanned 14 weeks. For clarity, revenue from the extra week last year added approximately 7 percentage points to the quarter's total revenue. Despite having one less week this year, we expect our December quarter, total company revenue to be similar to last year. We expect iPhone revenue to grow year-over-year on an absolute basis. We also expect to grow after normalizing for both last year's supply disruptions and the one extra week. We expect Mac year-over-year performance to significantly accelerate from the September quarter. We expect the year-over-year revenue performance for both iPad and Wearables, Home and Accessories to decelerate significantly from the September quarter due to a different timing of product launches. On iPad, we launched a new iPad Pro and iPad 10th Generation during the December quarter a year ago. For the Wearable category, last year we had the full December quarter benefit from the launches of the AirPods Pro 2nd Generation, the Watch SE, and the first Watch Ultra. For our Services business, we expect the average revenue per week to grow at a similar strong double-digit rate as it did during the September quarter. We expect gross margin to be between 45% and 46%. We expect OpEx to be between $14.4 billion and $14.6 billion. We expect OI&E to be around negative $200 million, excluding any potential impact from the mark-to-market of minority investments and our tax-rate to be around 16%. Finally, today our Board of Directors has declared a cash dividend of $0.24 per share of common stock, payable on November 16, 2023, to shareholders of record as of November 13, 2023. With that, let's open the call to questions.\n",
      "Suhasini Chandramouli: Thank you, Luca. We ask that you limit yourself to two questions. Operator, may we have the first question, please?\n",
      "Operator: Certainly. We will go ahead and take our first question from Mike Ng of Goldman Sachs. Please go ahead.\n",
      "Michael Ng: Hey. Good afternoon, and thank you very much for the questions. I just have a question on iPhone storage and demand versus iCloud. As demand for storage grows, are you seeing a mix-shift towards higher storage iPhone models or are consumers mostly opting for the same because of increased uptake of iCloud+? What are some of the strategic and financial considerations here and trade-offs, as you think about the mix shift towards higher storage models versus iCloud penetration? Thanks.\n",
      "Tim Cook: Michael, it's Tim. As you probably know, we started the line with the iPhone Pro Max at 256, and so we are seeing a different mix, if you will, this year than last year. Outside of that, not significant changes.\n",
      "Michael Ng: Great. Thank you. And as a separate follow-up, I was just wondering if you could talk a little bit about the market conditions on notebooks and desktops, and then any color that you can share regarding the timing of the Mac -- M3 MacBook Pros this year versus the M2 earlier in the calendar year? Thank you.\n",
      "Tim Cook: Yeah. We're thrilled to have announced the M3 lineup and get the new MacBook Pro, the new iMac out there. We couldn't be more excited about it. We -- as Luca said, with the lineup that we've got and the compare issue that we don't have during Q1, we anticipate a significant acceleration in the Mac space for Q1. To just repeat a little bit about the circumstances of the performance last quarter, in the year-ago June quarter, we had a factory disruption that lasted several weeks. The pent-up demand that resulted from that was filled in the September quarter, and that made the September quarter not only a record, but a substantial record. And obviously, we're now comparing against that for '23 and so that, I wouldn't look at the negative 34% as representative of the underlying business performance. It's sort of the net of it.\n",
      "Michael Ng: Excellent. That's very clear. Thank you, Tim.\n",
      "Tim Cook: Yeah.\n",
      "Suhasini Chandramouli: All right. Thanks, Mike. Can we have the next question, please?\n",
      "Operator: Our next question is from Aaron Rakers with Wells Fargo. Please go ahead.\n",
      "Aaron Rakers: Yeah. Thanks for taking the question and congratulations on the execution in the quarter. I'm curious, if you could help us characterize what the demand environment you're seeing in China looks like. How has the reception been to the iPhone 15? And kind of similar question to the prior one, how would you characterize the mix within China as you go through this current product cycle? And I have a follow-up.\n",
      "Tim Cook: Yeah. If you look at how we did in Greater China for the quarter, we came in at, on a revenue basis, minus 2. But one thing to keep in mind here is that the FX impact was nearly 6 points. So we grew in constant currency. And underneath that, if you look at the different -- the categories, iPhone actually set a September quarter record in mainland China. And the -- what pulled down the performance was a combination, largely of Mac and iPad. Services also grew during the quarter and the Mac and iPad suffered from the same issues that the company did with the compare issues to factory disruptions in Q3 that were filled subsequently in Q4 of '22. We had the -- in addition to that, we had the top four selling phones in urban China for last year, and I was -- I just took a trip over there and could not be more excited about the interactions I had with the customers and employees and others.\n",
      "Aaron Rakers: Yeah. And then, as a quick follow-up, I'm curious as we move towards more of an inflationary component pricing environment. Luca, how do we think about that effect? How you're thinking about the gross margin at the product level, as maybe component pricing starts to turn, what's been clearly very favorable over the last several quarters to more of an inflationary environment? Thank you.\n",
      "Luca Maestri: Well, as you've seen from our results in Q4 and the guidance for Q1, we're obviously experiencing very strong levels of gross margin. The 45.2% was a record for the September quarter. And then, the guidance for Q1 is obviously strong at 45% to 46%. Our gross margins are affected by multiple factors. Obviously, the commodity environment is one of them, as you mentioned. It's been a good environment in recent quarters. But equally important is the mix of what we sell. And obviously, growth in Services for us is favorable, and that has helped our company gross margin. Foreign exchange, on the other hand, has been a drag for us for several quarters, given the strength of the dollar. We don't provide guidance past the December quarter, which is a very important one for us because it's the beginning of the product cycle for many products. And so we feel very good, very confident about, this coming year, and I think the gross margin guidance reflects that.\n",
      "Aaron Rakers: Thank you.\n",
      "Suhasini Chandramouli: Thanks, Aaron. Can we have the next question, please?\n",
      "Operator: Our next question is from Erik Woodring with Morgan Stanley. Please go ahead.\n",
      "Erik Woodring: Awesome. Thank you very much for taking my questions. Maybe if I start, Luca, I know that the iPhone 15 Pro and Pro Max are constrained today, but I think some of your comments suggests you should be back to supply demand balance before quarter end. So, I guess, my question is, does your December quarter revenue guidance account for any supply constraints? And if so, is there any way to kind of quantify how much supply would be limiting your December quarter revenue performance? And then, I have a follow-up. Thank you.\n",
      "Luca Maestri: Yes. It's correct. We are constrained today on iPhone 15 Pro and iPhone 15 Pro Max. We're working very hard to get the product in the hands of all the customers that have ordered it. We expect, as of today, that we're going to be in supply demand balance by the end of the quarter. So the guidance reflects that.\n",
      "Erik Woodring: Okay, very clear. Thanks. And then, maybe for you and Tim. You guys have been on the leading end of -- edge of innovation across hardware, software, silicon, services. And I'm sure there's plenty of technology in kind of longer-term projects that you're investing in. How should we think about your capital intensity as we look to fiscal year '24, just given over the last few years, CapEx as a percentage of revenue had been relatively low compared to the eight years prior? So should we expect a step-up or kind of similar capital intensity? And what are the more notable moving pieces, if any, that we should be thinking about? Thanks.\n",
      "Luca Maestri: Well, the big areas of investment for us are tooling and equipment for manufacturing plants. Our investments in data centers and our investments in our own facilities, both corporate facilities and retail stores. And so, both for the tooling in our plants and our data center investments, we tend to have a bit of a hybrid model where we share some of the investments with our partners and suppliers and so maybe that's why you see sometimes a bit of variability. But over the last few years, we've made all the investments that we needed to make. And obviously, we're planning to make all the investments that we believe are needed and appropriate in order to continue to innovate.\n",
      "Erik Woodring: Great. Thanks so much for the color, guys.\n",
      "Suhasini Chandramouli: Thanks, Eric. Can we have the next question, please?\n",
      "Operator: Our next question is from David Vogt with UBS. Please go ahead.\n",
      "David Vogt: Great. Thanks, guys for taking my question. I know you covered China. I want to pivot to the US for a second. Obviously, iPhone and the business looks like it returned to growth in the quarter. But it's still relatively softer kind of where I thought it would be at this point in the cycle and some of the U.S. carriers obviously haven't been that particularly aggressive in promoting upgrades. So just wanted to kind of get a sense, first, what you're seeing from your partners in the U.S. kind of currently and going forward and what do you expect? And then, second, Luca, on the margins, I mean, is it fair to say that the mix in Q1 from a product versus services dynamic is kind of the key driver of the better gross margin guide as a whole relative to, let's say, the December quarter? Or is there anything else? I know you mentioned there's a lot of moving pieces, but is that the primary driver of the uplift in the margin? Thanks.\n",
      "Tim Cook: On the U.S. carriers and the U.S. business in general, it's really too early to call the iPhone cycle, particularly with the constraint around the Pro and the Pro Max and the U.S. tends to do quite well with those products. It's really too early to tell what the upgrade rates will be and what the switcher rates will be.\n",
      "Luca Maestri: On the margin side, if I understood your question correctly about the December quarter guidance, keep in mind that actually December is the quarter where our products business is tends to be very heavy because of the holiday season. And so the services gross margins that are accretive to total company had an impact, but not as meaningful as other quarters during the year and so I think that the main drivers of the guidance that we provided are the fact that we are seeing improved costs, and improved mix on our -- on the product side of the business, partially offset by foreign exchange, which continues to be a drag, both sequentially and on a year-over-year basis.\n",
      "David Vogt: Got it. So the weakness in iPad and Wearables are less of an impact on sort of the margin trajectory in the December quarter?\n",
      "Luca Maestri: That's correct.\n",
      "David Vogt: I guess?\n",
      "Luca Maestri: That's correct.\n",
      "David Vogt: Got it. Thanks, Luca.\n",
      "Suhasini Chandramouli: All right. Thanks, David. We'll take our next question, please.\n",
      "Operator: Our next question is from Amit Daryanani with Evercore. Please go ahead.\n",
      "Amit Daryanani: Yeah. Good afternoon. Thanks for taking my question. I have two as well. I guess, first off, just the Services growth rate, there's a tremendous acceleration I think in September quarter, the 16% growth. And it sounds like it’s going to hold there pretty well into December. Can you just talk about what is driving this acceleration? Are there a couple of products that have just stepped up in a very meaningful way? Just maybe flush out like what is driving this acceleration because it's fairly notable compared to what you've been seeing in the last few quarters.\n",
      "Luca Maestri: We had a really strong quarter across the border, Amit, because both geographically and from a product category standpoint, we saw very significant growth, I mentioned the records on a geographic basis. And from a category standpoint, literally, we set records in each one of the big categories. We had all-time record for App Store, for advertising, for cloud, video, AppleCare, payments and a September quarter record for Music. So it's hard to pick, one in particular because they all did well. And really then, we step back and we think about why is it that our Services business is doing well and it's because we have an installed base of customers that continues to grow at a very nice space and the engagement in our ecosystem continues to grow. We have more transacting accounts, we have more paid accounts, we have more subscriptions on the platform and we continue to add. We continue to add content and features. We're adding a lot of content on TV+, new games on Apple Arcade, new features, new storage plans for iCloud. So it's a combination of all these things and the fact that the engagement in the ecosystem is improving, and therefore, it benefits every service category.\n",
      "Amit Daryanani: Got it. That's really helpful. And then, maybe if I could ask you about Vision Pro, which I believe is supposed to be launched more broadly sometime in 2024, in the early part of the year. I'm curious how different do you think the launch and the consumer education of this product or a new category will be versus other things like AirPods or Apple Watch that you've done. And then, perhaps any themes I think that's set out to you from the developers that have been able to use this and the developer labs, what feedback have you gotten from them?\n",
      "Tim Cook: Yeah. That's a great question. There is a tremendous amount of excitement around the Vision Pro and we're -- we've been very happy to share it with developers, and we have developer labs set up in different parts of the world so that they can actually get their hands on it and are working on apps and I've been fortunate enough to see a number of those. And there is some real blow away kinds of things that are coming out, and so that all looks good. To answer your question about is it similar to AirPods or Apple Watch, I would say, no. There's never been a product like the Vision Pro. And so, we're purposely bringing it out in our stores only, so we can really put a great deal of attention on the last mile of it. We'll be offering demos in the stores and it will be very different process than the -- a normal grab-and-go kind of process.\n",
      "Amit Daryanani: Perfect. Thank you.\n",
      "Suhasini Chandramouli: Thanks, Amit. We'll take the next question, please.\n",
      "Operator: Our next question is from Harsh Kumar with Piper Sandler. Please go ahead.\n",
      "Harsh Kumar: Yeah. Hey, thanks for the question and congratulations on tremendous execution in a very tough macro. Actually, Tim, the last question is a perfect segue here, given what you are doing with your Vision Pro. So lots of companies are experimenting with generative AI. I'm curious about what kind of efforts you have. I'm sure there are segues into Pro Vision that you have, but I was curious about if you can give us a glimpse on how you might be able to monetize some of these efforts of generative AI.\n",
      "Tim Cook: If you kind of zoom out and look at what we've done on AI and machine learning and how we've used it, we view AI and machine learning as fundamental technologies, and they're integral to virtually every product that we ship. And so just recently, when we shipped iOS 17, it had features like Personal Voice and Live Voicemail. AI is at the heart of these features. And then, you can go all the way to then lifesaving features on the launch end of phone like fall detection, crash detection, ECG on the watch. These would not be possible without AI. And so, we don't label them as such, if you will. We label them as to what their consumer benefit is. But at the fundamental technology behind it is AI and machine learning. In terms of generative AI, we have -- obviously, we have work going on. I'm not going to get into details about what it is, because -- as you know, we don't -- we really don't do that. But you can bet that we're investing, we're investing quite a bit, we're going to do it responsibly and it will -- you will see product advancements over time that where the -- those technologies are at the heart of them.\n",
      "Harsh Kumar: Thanks, Tim. Very clear. And for my follow-up, I had a philosophical question. So, you guys always try to provide the best experience for consumers. To that end, I think, over the last decade you in-sourced a lot of important chips in your phones, in your Macs, iPads, so on and so forth. And that was, I think, a function that ARM wasn't around in the industry from a merchant angle. But now, we see these the silicon guys, the chip guys moving to ARM architecture. So my question to you is, has the move to internal silicon been economically profitable proposition for Apple? Or is it -- or is it a strategic one, where you simply need to own this and it's vital to your products for the consumer experience or maybe there's a path back to chip vendors at some point in time?\n",
      "Tim Cook: It's really enabled us to build products that we could not build without doing it ourselves. And as you know, we like to own the primary technologies in the products that we ship and arguably, the silicon is at the heart of the primary technologies, and so, no, I don't see going back. I am happier today than I was yesterday, than I was last week that we made the transition that we've made, and I see that benefit every day of it.\n",
      "Harsh Kumar: Thanks, Tim.\n",
      "Tim Cook: Yeah.\n",
      "Suhasini Chandramouli: Thank you, Harsh. We'll take the next question, please.\n",
      "Operator: Our next question is from Wamsi Mohan from Bank of America. Please go ahead.\n",
      "Wamsi Mohan: Yes. Thank you so much. Tim, over the last decade, pretty much you've gained a lot of share in China. As you look, your -- some of the domestic players are starting to re-emerge, especially in the high-end phone space. I know you touched on China. But how would you see Apple's positioning and opportunity for continued share gains, particularly in China? And how was the linearity in China from a demand perspective? And I have a follow-up, please.\n",
      "Tim Cook: In the September quarter, we set an iPhone record -- revenue record in China and we're very proud of that and we obviously grew. The market predictions that I've seen, we've had the market contracting. And so if that's -- if those are correct, then we gained share last quarter. And so we are very proud of that, I don't know what every quarter will hold. And obviously, we just give a bit of color on the current quarter. But over the long term, I view China as an incredibly important market and I'm very optimistic about it.\n",
      "Wamsi Mohan: Okay. Thanks, Tim. And as a follow-up, you obviously had a great Services quarter and part of your Services business has these licensing relationships with research partners, where you serve a very important distribution function for them. Can you talk about how you think about these relationships and potentially some of the options maybe Apple has to mitigate some of the risks, given some of the scrutiny on with some of the research partners? Thank you so much.\n",
      "Luca Maestri: They are important relationships. And as you know, we don't get into our commercial relationships in the call. I see them as important and we make decisions that are in the best interest of our users or what we feel is in the best interest of our users. And that's kind of what we've done in the past and how we've -- how we'll run the show in the future as well.\n",
      "Wamsi Mohan: Okay. Thank you, Tim.\n",
      "Suhasini Chandramouli: Thank you, Wamsi. Can we have the next question, please.\n",
      "Operator: Our next question comes from Krish Sankar with TD Cowen. Please go ahead.\n",
      "Krish Sankar: Yeah. Hi. Thanks for taking the question. I had two of them too. First one, Luca, thanks for the color on gross margin. And when I look at it over the last four quarters, even if on a year-over-year basis revenue declined, the gross margins have improved. And I understand Services definitely helped. I'm just kind of curious, when you look at on a go forward basis, are most of the big step functions and cost reductions like the Mac Silicon conversion, et cetera, that are done or is there more room for margin expansion from here? And then, I had a follow-up.\n",
      "Luca Maestri: Well, on the product side, as you know, we -- when we launch new products, the cost structures of those products tend to be higher than the products that they replace. It happens because we are always adding new technologies, new features, and then, we worked through the cost curve over the lifecycle of the product and we tend to get benefits as time goes by. The guidance that we provided for December reflects all that and so we're starting from a better position than a year ago or than, in the past, in general. There are other factors that play a role. For example, the mix of products that we sell. Not every product has the same gross margin profile, and so our guidance, our results are reflective of that. And also, within a specific product category, a lot depends on the kind of models that we sell because they have different margin profiles. I think one of the things that we've done well over the last few years is to offer more affordability solutions to our customers in the form of instalment plans, trading options, and spend -- low-cost financing in general. And what that has accomplished is reduced the affordability threshold for our customers and therefore, they can, buy at the top of our product ranges. That has been a big factor in the reason for our margin expansion. We don't provide guidance or color past the current quarter because there's so many different variables that affect gross margins, but we obviously feel very good about the trajectory that we've had in 2023 and now, the guidance that we provide for the beginning of our fiscal '24. And we need some of these things because, obviously, their foreign exchange environment has been difficult and has been a bit of a drag for us. But net-net, we're very pleased where we are.\n",
      "Krish Sankar: Got it. Thanks for that, Luca. And then, I have a follow-up for Tim. Obviously, you're seeing amazing momentum in India. I'm just kind of curious how do you look at -- when you look at the India growth opportunity on these hardware units, how to think about ASP relative to that versus like the rest of the geographies? And is there a way to compare or contrast India, growth momentum versus China maybe a decade ago or so at the same point in the rollout of, the share gains in that geography?\n",
      "Tim Cook: Yeah. It's a great question. We had an all-time revenue record in India. We grew very strong double-digits. It's an incredibly exciting market for us and a major focus of ours. We have low share in a large market, and so it would seem there's a lot of headroom there. The ASPs, I haven't looked at them most recently, but I'm sure that they're lower than the worldwide. But that doesn't bother us at all. It just -- and in terms of the similarity, I would say, each country has its own journey. And I wouldn't want to play the comparison game. But we see an extraordinary market, a lot of people moving into the middle class, distribution is getting better, lots of positives. We put two retail stores there, as you know. They're doing better than we anticipated. It's still early going, but they're off to a good start and I couldn't be happier with how things are going at the moment.\n",
      "Krish Sankar: Thanks, Tim.\n",
      "Suhasini Chandramouli: Thank you, Krish. We'll now take our next question, please.\n",
      "Operator: Our next question is from Ben Reitzes with Melius Research. Please go ahead.\n",
      "Ben Reitzes: Hey. Thanks a lot. I appreciate the question. Tim, I appreciate all your commentary around China. It was great to kind of hear about the growth potential there, your optimism. I wanted to also ask about the supply chain and where is your priority? Do you have a priority to diversify your supply chain? How do you feel about Apple's supply chain around the world? And in particular, what do you think about further investments in the U.S. as well?\n",
      "Tim Cook: Our supply chain is truly global, and so we're investing all over the world, including in the United States, we were very focused on advanced manufacturing for the U.S. and have worked on a number of different projects in the U.S., whether that's our venture with Corning on the glass or Face ID module or semiconductors. And so all of these are our advanced manufacturing and I think exactly the kinds of things that the U.S. would be and are very, very good at. We also invested in other regions of the world and we're continually optimizing the chain. And so we -- the moment we learned something that didn't work exactly right, we are tweaking it. And so we're going to continue to do that. But at the end of day, it will still be a global supply chain.\n",
      "Ben Reitzes: Got it. Thanks.\n",
      "Tim Cook: Yeah.\n",
      "Ben Reitzes: Next one for Luca. Just really quick on the extra week dynamic. There was also last year an issue with the iPhone production, where there was the COVID lockdowns in China. Is it possible to give some color around what that -- I guess, having a normalized supply chain somewhat this year, what that benefit is this year and maybe contrast that with the 7 point hit from the extra week? Thanks a lot.\n",
      "Luca Maestri: Yeah. Thanks for the question, Ben. I mentioned during the prepared remarks the extra week is 7 points of revenue. We did have disruptions, supply disruptions last year on the phone, on the 14 Pro and Pro Max in the December quarter a year ago. And when we normalize for those two factors, and I said it during the call, we still expect to grow on iPhone. So you take into account the, the loss of the extra week, you compare it with the supply disruptions that are not going to repeat, hopefully, this year. And when you normalize for those two things, we still expect to grow on iPhone.\n",
      "Ben Reitzes: Thanks a lot everybody. Appreciate it, Luca.\n",
      "Suhasini Chandramouli: Thank you, Ben. And we'll take the last question now.\n",
      "Operator: Our last question comes from Richard Kramer with Arete Research. Please go ahead.\n",
      "Richard Kramer: Thank you very much. Tim, first off, if we look over the past two years, Apple sales are about $18 billion higher and R&D is up by about 8% -- $8 billion or over a third higher. Can you give us a sense of some of the main components or drivers behind that increase in innovation spend? Is it Apple Silicon, is it new products like Vision Pro or is it content to support new services? I think that's one of the top questions investors have. Thanks.\n",
      "Tim Cook: Sure. It's a number of things, Richard. It's the -- some things I can't talk about, its Vision Pro, it's AI and ML, it's the silicon investment that we're making, the transition with the Mac and other silicon. It's sort of all of those things and -- but I think you would find that the R&D expenditure in the aggregate looks very competitive versus others.\n",
      "Luca Maestri: And I would add, Richard, on this front. Some of the investments that we're making in R&D are also one of the drivers for the gross margin expansion. So I think it's important to think about it that way.\n",
      "Richard Kramer: That's great. And Luca, you mentioned -- or Tim mentioned college students choosing Mac. Then, you mentioned the record Services revenue. What other metrics do you think you could provide to help investors understand how Apple measures and increases customer lifetime value, especially when we see a lot of users entering the ecosystem with a relatively lower-priced products or even refurbished devices? So you're growing your ecosystem, but how do you think about growing customer lifetime value over the long run?\n",
      "Luca Maestri: Well, some of the metrics that I mentioned before, obviously, we look at the installed base of active devices. We see, we want to make sure that, the customers that we acquire remain with us and so we have good visibility over that, and we pay a lot of attention to the behavior of the installed base, both by product and by geography. And then, we look at the daily engagement in the ecosystem. So that's why we pay a lot of attention on things like transacting accounts, paid accounts, we want to see if, in fact, we are able to move our customers from a free model to a paid model over time. That's obviously very, very important for us. And so, on this, we keep track of all these things and that's -- and then what we do, because I think it's really important is that over time, we add new services and that, obviously, like, for example, the progress that we've made in payments in recent years, very, very important because we've attracted more and more people that are actually now using additional features on our devices and we are able to monetize that, right. So we take all that into account, we understand what happens when a customer joins us, when they buy a primary device versus a used device, we understand their behavior, in different markets and so on. So we have, I think, pretty good visibility. And I think the progress that we're making in Services, we did $85 billion in the last 12 months. It's -- that's a size of a Fortune 50 and significantly bigger than it was just a couple of years ago.\n",
      "Richard Kramer: Absolutely. Thanks very much.\n",
      "Suhasini Chandramouli: Thank you, Richard. A replay of today's call will be available for two weeks on Apple Podcasts, as a webcast on apple.com/investor and via telephone. The number for the telephone replay is 866-583-1035. Please enter confirmation code 0106234 followed by the pound sign. These replays will be available by approximately 5 PM Pacific Time today. Members of the press with additional questions can contact Josh Rosenstock at 408-862-1142 and financial analysts can contact me, Suhasini Chandramouli, with additional questions at 408-974-3123. Thank you again for joining us today.\n",
      "Operator: Once again, this does conclude today's conference. We do appreciate your participation.\n"
     ]
    }
   ],
   "source": [
    "url = \"https://discountingcashflows.com/api/transcript/?ticker=AAPL&quarter=Q4&year=2023&key=6e9d241b-f336-4237-8935-2d70cd133969\" \n",
    "headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "    }\n",
    "response = requests.get(url, headers=headers)\n",
    "print(response.json()[0][\"content\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
